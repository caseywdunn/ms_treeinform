@article{boussau2013genome,
  title={Genome-scale coestimation of species and gene trees},
  author={Boussau, Bastien and Sz{\"o}ll{\H{o}}si, Gergely J and Duret, Laurent and Gouy, Manolo and Tannier, Eric and Daubin, Vincent},
  journal={Genome research},
  volume={23},
  number={2},
  pages={323--330},
  year={2013},
  publisher={Cold Spring Harbor Lab}
}

@article{Davidson2014,
abstract = {Next generation sequencing has made it possible to perform differential gene expression studies in non-model organisms. For these studies, the need for a reference genome is circumvented by performing de novo assembly on the RNA-seq data. However, transcriptome assembly produces a multitude of contigs, which must be clustered into genes prior to differential gene expression detection. Here we present Corset, a method that hierarchically clusters contigs using shared reads and expression, then summarizes read counts to clusters, ready for statistical testing. Using a range of metrics, we demonstrate that Corset out-performs alternative methods. Corset is available from https://code.google.com/p/corset-project/.},
author = {Davidson, N M and Oshlack, A},
doi = {10.1186/PREACCEPT-2088857056122054},
isbn = {1465-6914 (Electronic)$\backslash$r1465-6906 (Linking)},
issn = {1465-6906},
journal = {Genome Biol},
number = {7},
pages = {410},
pmid = {25063469},
title = {{Corset: enabling differential gene expression analysis for}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/25063469},
volume = {15},
year = {2014}
}

@article{Dunn2009,
doi = {10.1016/J.CUB.2009.02.009},
issn = {0960-9822},
author = {Dunn, Casey W},
journal = {Current Biology},
mendeley-groups = {treeinform},
month = {mar},
number = {6},
pages = {R233--R234},
publisher = {Cell Press},
title = {{Siphonophores}},
url = {http://www.sciencedirect.com/science/article/pii/S0960982209006757?via{\%}3Dihub},
volume = {19},
year = {2009}
}

@article{Dunn2013,
abstract = {BACKGROUND: In the past decade, transcriptome data have become an important component of many phylogenetic studies. They are a cost-effective source of protein-coding gene sequences, and have helped projects grow from a few genes to hundreds or thousands of genes. Phylogenetic studies now regularly include genes from newly sequenced transcriptomes, as well as publicly available transcriptomes and genomes. Implementing such a phylogenomic study, however, is computationally intensive, requires the coordinated use of many complex software tools, and includes multiple steps for which no published tools exist. Phylogenomic studies have therefore been manual or semiautomated. In addition to taking considerable user time, this makes phylogenomic analyses difficult to reproduce, compare, and extend. In addition, methodological improvements made in the context of one study often cannot be easily applied and evaluated in the context of other studies.$\backslash$n$\backslash$nRESULTS: We present Agalma, an automated tool that constructs matrices for phylogenomic analyses. The user provides raw Illumina transcriptome data, and Agalma produces annotated assemblies, aligned gene sequence matrices, a preliminary phylogeny, and detailed diagnostics that allow the investigator to make extensive assessments of intermediate analysis steps and the final results. Sequences from other sources, such as externally assembled genomes and transcriptomes, can also be incorporated in the analyses. Agalma is built on the BioLite bioinformatics framework, which tracks provenance, profiles processor and memory use, records diagnostics, manages metadata, installs dependencies, logs version numbers and calls to external programs, and enables rich HTML reports for all stages of the analysis. Agalma includes a small test data set and a built-in test analysis of these data. In addition to describing Agalma, we here present a sample analysis of a larger seven-taxon data set. Agalma is available for download at https://bitbucket.org/caseywdunn/agalma.$\backslash$n$\backslash$nCONCLUSIONS: Agalma allows complex phylogenomic analyses to be implemented and described unambiguously as a series of high-level commands. This will enable phylogenomic studies to be readily reproduced, modified, and extended. Agalma also facilitates methods development by providing a complete modular workflow, bundled with test data, that will allow further optimization of each step in the context of a full phylogenomic analysis.},
author = {Dunn, Casey W and Howison, Mark and Zapata, Felipe},
file = {:Users/august/Library/Application Support/Mendeley Desktop/Downloaded/Dunn, Howison, Zapata - 2013 - Agalma an automated phylogenomics workflow.pdf:pdf},
journal = {BMC bioinformatics},
keywords = {assembly,homology,phylogenetics,pipeline,transcriptomes,workflow},
pages = {330},
title = {{Agalma: an automated phylogenomics workflow.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3840672},
volume = {14},
year = {2013}
}

@article{Fu2012,
abstract = {CD-HIT is a widely used program for clustering biological sequences to reduce sequence redundancy and improve the performance of other sequence analyses. In response to the rapid increase in the amount of sequencing data produced by the next-generation sequencing technologies, we have developed a new CD-HIT program accelerated with a novel parallelization strategy and some other techniques to allow efficient clustering of such datasets. Our tests demonstrated very good speedup derived from the parallelization for up to ∼24 cores and a quasi-linear speedup for up to ∼8 cores. The enhanced CD-HIT is capable of handling very large datasets in much shorter time than previous versions.},
author = {Fu, Limin and Niu, Beifang and Zhu, Zhengwei and Wu, Sitao and Li, Weizhong},
doi = {10.1093/bioinformatics/bts565},
isbn = {1367-4811 (Electronic)$\backslash$n1367-4803 (Linking)},
issn = {13674803},
journal = {Bioinformatics},
mendeley-groups = {treeinform},
number = {23},
pages = {3150--3152},
pmid = {23060610},
title = {{CD-HIT: Accelerated for clustering the next-generation sequencing data}},
volume = {28},
year = {2012}
}

@article{gernhard2008conditioned,
  title={The conditioned reconstructed process},
  author={Gernhard, Tanja},
  journal={Journal of theoretical biology},
  volume={253},
  number={4},
  pages={769--778},
  year={2008},
  publisher={Elsevier}
}

@article{grabherr-2011,
annote = {10.1038/nbt.1883},
author = {Grabherr, Manfred G and Haas, Brian J and Yassour, Moran and Levin, Joshua Z and Thompson, Dawn A and Amit, Ido and Adiconis, Xian and Fan, Lin and Raychowdhury, Raktima and Zeng, Qiandong and Chen, Zehua and Mauceli, Evan and Hacohen, Nir and Gnirke, Andreas and Rhind, Nicholas and di Palma, Federica and Birren, Bruce W and Nusbaum, Chad and Lindblad-Toh, Kerstin and Friedman, Nir and Regev, Aviv},
isbn = {1087-0156},
journal = {Nat Biotech},
mendeley-groups = {treeinform},
number = {7},
pages = {644--652},
publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
title = {{Full-length transcriptome assembly from RNA-Seq data without a reference genome}},
url = {http://dx.doi.org/10.1038/nbt.1883},
volume = {29},
year = {2011}
}

@article{han2013estimating,
  title={Estimating gene gain and loss rates in the presence of error in genome assembly and annotation using CAFE 3},
  author={Han, Mira V and Thomas, Gregg WC and Lugo-Martinez, Jose and Hahn, Matthew W},
  journal={Molecular biology and evolution},
  volume={30},
  number={8},
  pages={1987--1997},
  year={2013},
  publisher={SMBE}
}

@article{kullback1951,
author = "Kullback, S. and Leibler, R. A.",
doi = "10.1214/aoms/1177729694",
fjournal = "The Annals of Mathematical Statistics",
journal = "Ann. Math. Statist.",
month = "03",
number = "1",
pages = "79--86",
publisher = "The Institute of Mathematical Statistics",
title = "On Information and Sufficiency",
url = "http://dx.doi.org/10.1214/aoms/1177729694",
volume = "22",
year = "1951"
}

@MISC{Plummer03jags,
    author = {Martyn Plummer},
    title = {JAGS: A program for analysis of Bayesian graphical models using Gibbs sampling},
    year = {2003}
}

@article{Rand1971,
abstract = {Many intuitively appealing methods have been suggested for clustering data1 however, interpretation of their resu/ts has been hindered by the lack of obiective criteria. This article proposes several criteria which isolate speciflc aspects of the performance of a method, such as its retrieval of inherent structure, its sensitivity to resampling and the stability of its results in the light of new data. These criteria depend on a measure of similarity between two different clusterings of the same sei of data; the measure essentially considers how each pair of data points is assigned in each clustering.},
archivePrefix = {arXiv},
arxivId = {1704.01036},
author = {Rand, William M.},
doi = {10.1080/01621459.1971.10482356},
eprint = {1704.01036},
isbn = {0162-1459},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
number = {336},
pages = {846--850},
pmid = {1000172896},
title = {{Objective criteria for the evaluation of clustering methods}},
volume = {66},
year = {1971}
}
