---
title: "treeinform manuscript figure generator"
output:
  pdf_document: default
  html_notebook: default
  html_document: default
---

```{r, setup, include=FALSE}
library(ape)
library(ggplot2)
library(dplyr)
library(hutan)
library(treeio)
library(parallel)
library(dplyr)
library(runjags)

cores = detectCores()
if (cores < 1) { cores = 1 }
set.seed(1287234)

l=0.00617025240076
m=0.00634249271090

source("code/functions.R")
```

This is a notebook snippet to generate some of the figures for the treeinform manuscript.

# Figure 1: Gene tree before and gene tree after

# Figure 2a: Percentage of reassigned tips

The percentage of reassigned tips is plotted below. The original assembly had 315,041 genes, with at most 23,396 possible candidates for reassignment.

```{r, fused_percentage}
orig_assembly = 315041
t=1:10 # thresholds were 5000*10^(-t)
threshold = 5000*10^(-t)
# numbers taken from slurm output
reassigned = c(23396, 23396, 22792, 13380, 7944, 5560, 5229, 5219, 5092, 0)
newly_created = c(9009, 9009, 9028, 6006, 3663, 2539, 2381, 2376, 2393, 0)
revised_assembly = c(300654, 300654, 301277, 307667, 310760, 312020, 312193, 312198, 312342, 315041)
fused.df <- data.frame(threshold,reassigned, newly_created, revised_assembly)
fused.df.percents <- transmute(fused.df, threshold, reassigned=reassigned/315041)

ggplot(fused.df.percents, aes(threshold, reassigned)) + geom_jitter() + scale_x_log10() + ggtitle("Percentage of reassigned genes vs threshold") + xlab("Threshold") + ylab("Percentage")
```

# Figure 2b: Theoretical duplication times compared to empirical duplication times from before treeinform and after treeinform

In order to validate that treeinform produces more accurate gene trees, we compare the density of duplication times under a birth-death model with parameter $\lambda$=birth rate, $\mu$=death rate, and $t_{or}=\{ t_{or,1}, t_{or,2}, \ldots, t_{or,K} \}$=time of tree origin for gene families $1, \ldots, K$ to the distribution of estimated duplication times for gene trees from before treeinform, and gene trees from after treeinform under 3 different thresholds: 50, 0.05, and 5e-05.

For the distribution of estimated duplication times of gene trees before and after treeinform, we used phylDOG to estimate duplication times in units of expected number of substitutions, then used calibrated branch lengths to units of time under a scheme similar to ms_comparative_expression.

The pdf of duplication times under a birth-death model and given a time of origin is:
$$
f(x_{i,k} | t_{or,k}, \lambda, \mu) = (\lambda - \mu)^2 \frac{e^{-(\lambda-\mu)x_i}}{(\lambda - \mu e^{-(\lambda - \mu)x_i})^2} \frac{\lambda - \mu e^{-(\lambda - \mu)t}}{1 - e^{-(\lambda - \mu)t}} 
$$
where $x_{i, k}$ represents duplication times $i$ from gene tree $G_k$, as derived by Gernhard 2008. To compute this, we first estimate $\lambda$ and $\mu$ using CAFE3 with the same fixed $t_{or}=1,000,000$ and $G=\{ G_1, \ldots, G_K \}$=gene family sizes for gene trees $1, \ldots, K$, then plug the $\lambda$ and $\mu$ estimates from CAFE in along with the same calibrated $t_{or,k}$s. A key assumption here is that the fixed $t_{or,k}$s allows for accurate comparisons between the theoretical density of duplication times and the estimated duplication times even if it is technically an incorrect estimate of the age of the gene trees (and species tree).

```{r, parse_trees, include=FALSE}
# make speciation calibration times (taken from chronos)
age <- c(0.1718036, 0.1430510, 0.2490215, 0.3227746, 0.5157844, 1.0000000)
clade <- c("Calycophora", "Agalmatidae", "Chodorophora", "Siphonophora", "Hydrozoa", "Cnidaria")
calibration_times = data.frame(age, clade, stringsAsFactors = FALSE)

#5299 gene trees + 5301 (missing 5300)
# try with 200
#s <- 1:200
#edges_before <- mclapply(s, function(x) #parse_gene_trees(processTree(paste0("../phyldog-before/", x, ".ReconciledTree"))), mc.cores = cores)
#edges_before <- edges_before[which(!unlist(mclapply(edges_before, is.null)))]
#save(edges_before, file="data/edges_before.Rdata")
#load("data/edges_before.Rdata")
#calibrated = mclapply(edges_before, function(x) calibrate_tree(x, calibration_times), mc.cores=cores)
#calibrated = calibrated[which(!is.na(calibrated))]
#dt_before = unlist(mclapply(calibrated, duplication_times, mc.cores=cores))
#dt_before = dt_before[which(!is.na(dt_before))]
#save(dt_before, file="data/dt_before.Rdata")
load("data/dt_before.Rdata")

#k <- 7000:7200
#edges_after <- edges_after[which(!unlist(mclapply(edges_after, is.null)))]
#save(edges_after, file="data/edges_after.Rdata")
#load("data/edges_after.Rdata")
#calibrated_after = mclapply(edges_after, function(x) calibrate_tree(x, calibration_times), mc.cores=cores)
#calibrated_after = calibrated_after[which(!is.na(calibrated_after))]
#threshold_5 = unlist(mclapply(calibrated_after, duplication_times, mc.cores=cores))
#threshold_5 = threshold_5[which(!is.na(threshold_5))]
#save(threshold_5, file="data/dt_threshold-5.Rdata")
load("data/dt_threshold-5.Rdata")

l <- 27804:28004
#threshold_2 <- dt_phyldog(l, "../threshold-2/", calibration_times)
#save(threshold_2, file="data/dt_threshold-2.Rdata")
load("data/dt_threshold-2.Rdata")

# don't have threshold_6 already downloaded dumbass
#threshold_6 <- dt_phyldog(l, "../threshold-6/", calibration_times)
#save(threshold_6, file="data/dt_threshold-6.Rdata")
#load("data/dt_threshold-6.Rdata")

#threshold_8 <- dt_phyldog(l, "../threshold-8/", calibration_times)
#save(threshold_8, file="data/dt_threshold-8.Rdata")
load("data/dt_threshold-8.Rdata")
```

```{r, fig2b}
dt <- c(dt_before, threshold_5, threshold_2, threshold_8)
l1 = length(dt_before)
l2 = length(threshold_5)
l3 = length(threshold_2)
l4 = length(threshold_8)
#l5 = length(threshold_6)
#grp <- rep(NA, l1+l2+l3+l4+l5)
grp <- rep(NA, l1+l2+l3+l4)
grp[1:l1] <- "Before"
grp[l1+1:l2] <- "threshold=0.05"
grp[l1+l2+1:l3] <- "threshold=50"
grp[l1+l2+l3+1:l4] <- "threshold=5e-05"
#grp[l1+l2+l3+l4+1:l5] <- "threshold=0.005"
data = data.frame(dt, grp)
f = function(x) dup_pdf(x, 1, 0.617025240076, 0.6334249271090)
ggplot(data, aes(dt)) + geom_density(aes(group=grp, color=grp)) + stat_function(fun=f) + ggtitle("Density of inferred and theoretical duplication times\nunder different treeinform thresholds") + xlab("Duplication Times") + ylab("Density")
```

Additionally, we can run the Kolmogorov-Smirnov test on the CDFs of the thresholds to compare. The CDF of the theoretical distribution is:
$$
F(x_{i,k} | t=t_{or, k}, \lambda, \mu) = \frac{1 - e^{-(\lambda - \mu x_{i,k})}}{\lambda - \mu e^{-(\lambda - \mu)x_{i,k}}} \frac{\lambda - \mu e^{-(\lambda - \mu) t}}{1 - e^{-(\lambda - \mu) t}}
$$

```{r, ks}
theoretical = function(x) dup_cdf(x, 1, 0.617025240076, 0.6334249271090)
ks.test(dt_before, theoretical)
ks.test(threshold_2, theoretical)
ks.test(threshold_5, theoretical)
#ks.test(threshold_6, threoretical)
ks.test(threshold_8, theoretical)
```

The default threshold (threshold_5, which is 0.05) comes closest to the theoretical distribution.

# Figure 3: Mixture model fit

Under the assumption that transcript annotation errors bias duplication times towards 0 and can be modeled as a gamma distribution, we can view the empirical distribution of duplication times before treeinform as a 2-component mixture of the gamma distribution and the theoretical provided by Gernhard:

$$ P(x_{i,k}) = \pi_1 \Gamma(x_{i,k}|\alpha, \beta) + \pi_2 f(x_{i,k} | t_{or,k}=t, \lambda, \mu)$$
where $\Gamma(x_{i,k} | \alpha, \beta)$ is the pdf for the gamma distribution with shape $\alpha$ and rate $\beta$, and $f(x_{i,k} | t_{or,k} = t, \lambda, \mu)$ is the pdf for the duplication times under birth rate $\lambda$ and death rate $\mu$ from above. $\pi_1$ and $\pi_2$ denote the mixing proportions, thus $\pi_1 + \pi_2 = 1$.

```{r, runjags, include=FALSE}
#load("data/dt_before.Rdata")

# Data
#Y = dt_before
#N = length(dt_before)

# Initial values to get the chains started:
#alpha <- 1
#beta <- 1
#lambda <- 0.637025240076
#mu <- 0.614249271090
#t <- 1
#Constant <- 10

#Ones <- rep(1, N)

#results <- run.jags(model="code/runjags.txt", n.chains=3, thin=1)
#save(results, file="data/runjags_results.Rdata")
load("data/runjags_results.Rdata")
sum = summary(results)

alpha = sum[1,4]
beta = sum[2,4]
mu = sum[3,4]
lambda = sum[4,4]
p1 = sum[5,4]
p2 = sum[6,4]

mix2 <- lapply(dt_before, function(y) dup_pdf(y, 1, lambda, mu))

mix1 = function(x, p1=p1, alpha=alpha, beta=beta) { p1*dgamma(x,shape=alpha,scale=beta)}
mix2 = function(x, p2=p2, lambda=lambda,mu=mu) { p2*dup_pdf(x,1,lambda,mu)}
```

We use Bayesian Gibbs Sampling with the Bernoulli Ones trick to infer the parameters $\alpha$, $\beta$, $\lambda$, and $\mu$ as well as the mixing proportions $p_1$ and $p_2$. The package we use is Just Another Gibbs Sampler (JAGS).

From JAGS we get the parameter estimates as:
```{r, runjags_viz}
sum

ggplot(data.frame(x=dt_before)) + geom_histogram(aes(x=x,y=..density..), fill="white", color="black") + stat_function(geom="line",fun=mix1,args=list(p1,alpha,beta),xlim=c(0.005,1), color="#FF000080")+stat_function(geom="line",fun=mix2,args=list(p2,lambda,mu),color="blue")

intersection = uniroot(function(x) mix1(x,p1,alpha,beta)-mix2(x,p2,lambda,mu), c(0,0.25))$root

intersection
```
along with a plot of the mixtures and the intersection point between the two densities for the mixture. This intersection point confirms that a threshold choice of around 0.05 is appropriate.

```{r, expectation, eval=FALSE}

edges_before.km <- kmeans(edges_before, 2)
edges_before.df <- data.frame(x = edges_before, cluster = edges_before.km$cluster)
edges_before.df %>%
  mutate(num = row_number()) %>%
  ggplot(aes(y = num, x = x, color = factor(cluster))) +
  geom_point() +
  ylab("Values") +
  ylab("Data Point Number") +
  scale_color_discrete(name = "Cluster") +
  ggtitle("K-means Clustering")
#comp1.prod <- dgamma(x=edges_before, shape=edges_before.summary.df$mu[1]^2/edges_before.summary.df$std[1]^2, rate=edges_before.summary.df$mu[1]/edges_before.summary.df$std[1]^2) * edges_before.summary.df$alpha[1]
#comp2.prod <- edges_before.df %>% mutate(pdf=f(x)*edges_before.summary.df$alpha[2]) %>% select(pdf)
#normalizer <- comp1.prod + comp2.prod
#comp1.post <- comp1.prod / normalizer
#comp2.post <- comp2.prod/normalizer
```

```{r, mixture}
```
